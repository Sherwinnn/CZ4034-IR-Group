{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\limju\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\limju\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "import re\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from statistics import mean \n",
    "import contractions\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>title</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>88 Seafood</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was my first time eating here. I can tell...</td>\n",
       "      <td>first time eat tell shd crayfish dish sooooooo...</td>\n",
       "      <td>0.434167</td>\n",
       "      <td>0.330795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>88 Seafood</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Considering that the dining area is next to a ...</td>\n",
       "      <td>consider din area be next prawn fish area migh...</td>\n",
       "      <td>0.385397</td>\n",
       "      <td>0.074921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>88 Seafood</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1st time came was 5 months ago. A decent Cze C...</td>\n",
       "      <td>st time come month ago decent cze char order c...</td>\n",
       "      <td>0.412037</td>\n",
       "      <td>0.186111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88 Seafood</td>\n",
       "      <td>5.0</td>\n",
       "      <td>First time experiencing prawning, we spend a g...</td>\n",
       "      <td>first time experience prawn spend good hr praw...</td>\n",
       "      <td>0.528030</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>88 Seafood</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Outgoing visit on Saturday, September 2023. Fi...</td>\n",
       "      <td>outgo visit saturday september fish shrimp cho...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>-0.138889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx       title  stars                                               text  \\\n",
       "0    1  88 Seafood    5.0  This was my first time eating here. I can tell...   \n",
       "1    2  88 Seafood    4.0  Considering that the dining area is next to a ...   \n",
       "2    3  88 Seafood    4.0  1st time came was 5 months ago. A decent Cze C...   \n",
       "3    4  88 Seafood    5.0  First time experiencing prawning, we spend a g...   \n",
       "4    5  88 Seafood    4.0  Outgoing visit on Saturday, September 2023. Fi...   \n",
       "\n",
       "                                        cleaned_text  subjectivity_score  \\\n",
       "0  first time eat tell shd crayfish dish sooooooo...            0.434167   \n",
       "1  consider din area be next prawn fish area migh...            0.385397   \n",
       "2  st time come month ago decent cze char order c...            0.412037   \n",
       "3  first time experience prawn spend good hr praw...            0.528030   \n",
       "4  outgo visit saturday september fish shrimp cho...            0.377778   \n",
       "\n",
       "   polarity_score  \n",
       "0        0.330795  \n",
       "1        0.074921  \n",
       "2        0.186111  \n",
       "3        0.183333  \n",
       "4       -0.138889  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in cleaned train data\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "train_df = train_df.dropna(subset=['cleaned_text']).reset_index(drop=True)\n",
    "train_df['polarity_score'] = train_df['polarity_score'].astype(float)\n",
    "train_df['subjectivity_score'] = train_df['subjectivity_score'].astype(float)\n",
    "train_df['stars'] = train_df['stars'].astype(float)\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='stars', ylabel='count'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_df, x=\"stars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis \n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  \n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "        u\"\\U00002500-\\U00002BEF\"  \n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  \n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def remove_stopwords(reviews):\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    custom_stopwords = {'not', 'is', 'but'}\n",
    "    STOPWORDS -= custom_stopwords\n",
    "    if STOPWORDS is None:\n",
    "        STOPWORDS = set(stopwords.words('english'))\n",
    "    # Split the reviews into words and remove stopwords\n",
    "    words = reviews.split()\n",
    "    words_filtered = [word for word in words if word not in STOPWORDS]\n",
    "    \n",
    "    # Join the filtered words back into a string\n",
    "    filtered_reviews = ' '.join(words_filtered)\n",
    "    \n",
    "    return filtered_reviews\n",
    "\n",
    "def remove_extra_whitespace(reviews):\n",
    "    return \" \".join(reviews.split())\n",
    "\n",
    "def get_wordnet_pos(text):\n",
    "    # Map POS tag to first character lemmatize() accepts\n",
    "    tags = nltk.pos_tag(text)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    tags = [tag_dict.get(tag[1][0],  wordnet.NOUN) for tag in tags]\n",
    "    return tags\n",
    "\n",
    "def lemmaSentence(reviews):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemma_text = ''\n",
    "    tok_text = word_tokenize(reviews)\n",
    "    tags = get_wordnet_pos(tok_text)\n",
    "    for i in range(len(tok_text)):\n",
    "        lemma_text = lemma_text + ' ' + lemmatizer.lemmatize(tok_text[i], tags[i])\n",
    "    return lemma_text[1:]\n",
    "\n",
    "def lower_case(review):\n",
    "    return review.lower()\n",
    "\n",
    "# change contraction words such sa I'm = I am, shouldn't = should not\n",
    "def change_contractions(review):\n",
    "    \n",
    "    expanded_words = [contractions.fix(word) for word in review.split()]\n",
    "\n",
    "    expanded_review = ' '.join(expanded_words)\n",
    "    return expanded_review\n",
    "\n",
    "# Remove Punctuations\n",
    "def remove_punctuations(review):\n",
    "    \n",
    "    new_review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "    return new_review\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(review):\n",
    "    \n",
    "    mapping = str.maketrans('', '', string.digits)\n",
    "    new_review = review.translate(mapping)\n",
    "    \n",
    "    return new_review\n",
    "\n",
    "\n",
    "def clean_text(data):\n",
    "\n",
    "    data = data.apply(lower_case)\n",
    "    data = data.apply(change_contractions)\n",
    "    data = data.apply(remove_emojis)\n",
    "    data = data.apply(remove_punctuations)\n",
    "    data = data.apply(remove_numbers)\n",
    "    data = data.apply(remove_stopwords)\n",
    "    data = data.apply(remove_extra_whitespace)\n",
    "    data = data.apply(lemmaSentence)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def clean_text_withstopword(data):\n",
    "\n",
    "    data = data.apply(lower_case)\n",
    "    data = data.apply(change_contractions)\n",
    "    data = data.apply(remove_emojis)\n",
    "    data = data.apply(remove_punctuations)\n",
    "    data = data.apply(remove_numbers)\n",
    "    #data = data.apply(remove_stopwords)\n",
    "    data = data.apply(remove_extra_whitespace)\n",
    "    data = data.apply(lemmaSentence)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['cleaned_text'] = clean_text(testdf.text)\n",
    "def anno2binary(text):\n",
    "    if text=='POSITIVE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "testdf['Binary_anno'] = testdf.Polarity_Anno1.apply(anno2binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign polarity to train data\n",
    "- Stars 4 and above, positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign positive/negative labels method 1\n",
    "train_df['sentiment'] = 0\n",
    "train_df.loc[train_df['stars'] >=4, 'sentiment'] = 1 #positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X = train_df['cleaned_text']\n",
    "train_df_y = train_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want stemmed instead of lemmatized words\n",
    "def stemSentence(reviews):\n",
    "    stemmer = PorterStemmer()\n",
    "    stem_text = ''\n",
    "    tok_text = word_tokenize(reviews)\n",
    "    for i in range(len(tok_text)):\n",
    "        stem_text = stem_text + ' ' + stemmer.stem(tok_text[i])\n",
    "    return stem_text[1:]\n",
    "\n",
    "train_df_X = train_df_X.apply(stemSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize distribution. We must balance.\n",
    "sns.countplot(train_df, x=\"sentiment\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key with maximum value: c\n",
      "Maximum value: 20\n"
     ]
    }
   ],
   "source": [
    "def max_key_for_max_value(dictionary):\n",
    "    if not dictionary:  # If the dictionary is empty\n",
    "        return None, None\n",
    "\n",
    "    max_value = max(dictionary.values())  # Find the maximum value in the dictionary\n",
    "    max_key = None\n",
    "\n",
    "    for key, value in dictionary.items():\n",
    "        if value == max_value:\n",
    "            max_key = key\n",
    "\n",
    "    return max_key, max_value\n",
    "\n",
    "# Example usage:\n",
    "my_dict = {'a': 10, 'b': 20, 'c': 20, 'd': 15}\n",
    "max_key, max_value = max_key_for_max_value(my_dict)\n",
    "print(\"Key with maximum value:\", max_key)\n",
    "print(\"Maximum value:\", max_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: TFIDF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "{'C': 0.5, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "{'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m svc \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m     39\u001b[0m svc\u001b[38;5;241m.\u001b[39mfit(X_train_vector, y_train_balanced)\n\u001b[1;32m---> 41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m f1 \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m param_f1\u001b[38;5;241m.\u001b[39mappend(f1)\n",
      "File \u001b[1;32mc:\\Users\\limju\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\limju\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    434\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\limju\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:481\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[0;32m    479\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# C is not useful here\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLIBSVM_IMPL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Find optimal hyperparameters\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'C': [0.5,1, 5, 10], 'kernel': ['rbf'], 'gamma':['scale','auto']}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X[train_index],train_df_X[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        svc = svm.SVC(**param)\n",
    "        svc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = svc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "        #print(\"Macro F1 Score:\", f1)\n",
    "    param_str = str(param)\n",
    "    print(param)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\", 0.8351423381221252)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key_for_max_value(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 1.2766022682189941s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "svc = svm.SVC(C= 1, gamma= 'scale', kernel= 'rbf') #Optimal hyperparameters here\n",
    "svc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text)\n",
    "y_test_pred = svc.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836.5957249081046"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1068/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.94      0.75       220\n",
      "           1       0.98      0.85      0.91       848\n",
      "\n",
      "    accuracy                           0.87      1068\n",
      "   macro avg       0.80      0.89      0.83      1068\n",
      "weighted avg       0.91      0.87      0.88      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: TFIDF + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 Score: 0.8088136927011607\n",
      "Macro F1 Score: 0.8078305710450226\n",
      "Macro F1 Score: 0.8139518088087925\n",
      "Macro F1 Score: 0.8030079718582818\n",
      "Macro F1 Score: 0.8012140902872777\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'n_estimators': [100,200,250], 'max_depth':[5,10,20,None],'ccp_alpha':[0], 'max_features':['sqrt'],'n_jobs':[-1]}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X[train_index],train_df_X[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        rfc = RandomForestClassifier(**param)\n",
    "        #rfc = RandomForestClassifier()\n",
    "\n",
    "        rfc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = rfc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "        print(\"Macro F1 Score:\", f1)\n",
    "    \n",
    "    param_str = str(param)\n",
    "    print(\"F1 Score:\", param_f1)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key_for_max_value(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 0.11025452613830566s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "rfc = RandomForestClassifier(ccp_alpha= 0, max_depth= None, max_features= 'sqrt', n_estimators= 250, n_jobs= -1, random_state=42) #Optimal hyperparameters here\n",
    "rfc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text)\n",
    "y_test_pred = rfc.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9686.677158815935"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1068/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.93      0.71       220\n",
      "           1       0.98      0.83      0.90       848\n",
      "\n",
      "    accuracy                           0.85      1068\n",
      "   macro avg       0.78      0.88      0.81      1068\n",
      "weighted avg       0.90      0.85      0.86      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: TFIDF + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: [0.8095733038890933, 0.804821005472856, 0.8296010773411608, 0.8139778684898411, 0.8127726635523194]\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'alpha':[1]}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X[train_index],train_df_X[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1,3))\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        nbc = MultinomialNB(**param)\n",
    "        nbc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = nbc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "        #print(\"Macro F1 Score:\", f1)\n",
    "    param_str = str(param)\n",
    "    print(\"F1 Score:\", param_f1)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"{'alpha': 1}\": 0.8141491837490541}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 1.335941s\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "nbc = MultinomialNB() #Optimal hyperparameters here\n",
    "nbc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text)\n",
    "start= datetime.datetime.now()\n",
    "for i in range(20):\n",
    "    X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text)\n",
    "    y_test_pred = nbc.predict(X_test_vector)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "t = end-start\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {t.total_seconds()}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15988.73004122188"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20*1068) / t.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70       220\n",
      "           1       0.98      0.81      0.89       848\n",
      "\n",
      "    accuracy                           0.84      1068\n",
      "   macro avg       0.77      0.87      0.79      1068\n",
      "weighted avg       0.89      0.84      0.85      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innovation - Stacked ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 0.8282756805419922s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "\n",
    "estimators = [#('nbc', MultinomialNB()), \n",
    "              ('rfc', RandomForestClassifier(n_jobs= -1,random_state=42)),\n",
    "              ('knc', KNeighborsClassifier()),]\n",
    "              #('svm', svm.SVC(C= 15, gamma= 'scale', kernel= 'rbf'))\n",
    "              #]\n",
    "\n",
    "#estimators = [('svm', svm.SVC(C= 1, gamma= 'auto', kernel= 'rbf'))]\n",
    "stackclf = StackingClassifier(estimators=estimators)\n",
    "\n",
    "\n",
    "stackclf.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text)\n",
    "y_test_pred = stackclf.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultinomialNB(), KNeighborsClassifier()]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackclf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289.425761361412"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1068) / (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.93      0.62       220\n",
      "           1       0.97      0.72      0.83       848\n",
      "\n",
      "    accuracy                           0.76      1068\n",
      "   macro avg       0.72      0.83      0.72      1068\n",
      "weighted avg       0.87      0.76      0.79      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innovation - Add POS tags to TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(text):\n",
    "    # Map POS tag to first character lemmatize() accepts\n",
    "    tags = nltk.pos_tag(text)\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    tags = [tag_dict.get(tag[1][0],  wordnet.NOUN) for tag in tags]\n",
    "    return tags\n",
    "\n",
    "def add_pos_tags_to_lemma(text):\n",
    "    #appends POS tag to end of each word\n",
    "    pos_text = ''\n",
    "    tok_text = word_tokenize(text)\n",
    "    tags = get_wordnet_pos(tok_text)\n",
    "    for i, word in enumerate(tok_text):\n",
    "        pos_text = pos_text + ' ' + f'{tok_text[i]}_{tags[i]}'\n",
    "    return pos_text\n",
    "\n",
    "def add_pos_tags_to_stem(text):\n",
    "    #appends POS tag to end of each word\n",
    "    stemmer=PorterStemmer()\n",
    "    pos_text = ''\n",
    "    tok_text = word_tokenize(text)\n",
    "    tags = get_wordnet_pos(tok_text)\n",
    "    for i, word in enumerate(tok_text):\n",
    "        pos_text = pos_text + ' ' + f'{stemmer.stem(tok_text[i])}_{tags[i]}'\n",
    "    return pos_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add POS labels behind each word\n",
    "train_df_X_POS = train_df_X.apply(add_pos_tags_to_lemma)\n",
    "#train_df_X_stem_POS = train_df_X.apply(add_pos_tags_to_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['cleaned_text_POS'] = testdf.cleaned_text.apply(add_pos_tags_to_lemma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF POS + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: [0.8177186905351013, 0.8185271522050939, 0.825887058504041, 0.8189530791461783, 0.8053814002089863]\n",
      "F1 Score: [0.8218483598273628, 0.8285821100745483, 0.8357168473613066, 0.8262399596282435, 0.8171117272240868]\n",
      "F1 Score: [0.8261709913201911, 0.8249493594924319, 0.8359864649986066, 0.8255868344091795, 0.8239411242228143]\n",
      "F1 Score: [0.8261709913201911, 0.8249493594924319, 0.8359864649986066, 0.8255868344091795, 0.8239411242228143]\n",
      "F1 Score: [0.8261709913201911, 0.8249493594924319, 0.8359864649986066, 0.8255868344091795, 0.8239411242228143]\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'C': [0.5,1, 5, 10,15], 'kernel': ['rbf'], 'gamma':['scale']}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X_POS, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X_POS[train_index],train_df_X_POS[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000, ngram_range=(1,3), stop_words=['_a','_n','_r','_v'])\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        svc = svm.SVC(**param)\n",
    "        svc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = svc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "    param_str = str(param)\n",
    "    print(\"F1 Score:\", param_f1)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"{'C': 15, 'gamma': 'scale', 'kernel': 'rbf'}\", 0.8273269548886447)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key_for_max_value(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 1.1655681133270264s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X_POS)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X_POS[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X_POS[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "svc = svm.SVC(C= 20, gamma= 'scale', kernel= 'rbf')\n",
    "svc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text_POS)\n",
    "y_test_pred = svc.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "916.2913670926313"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1068/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.92      0.73       220\n",
      "           1       0.98      0.84      0.90       848\n",
      "\n",
      "    accuracy                           0.86      1068\n",
      "   macro avg       0.79      0.88      0.82      1068\n",
      "weighted avg       0.90      0.86      0.87      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF POS + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: [0.7978159600936621, 0.7841882219636284, 0.7837597216537044, 0.7645321938666224, 0.782531476236497]\n",
      "F1 Score: [0.7878477165075104, 0.7959343617470864, 0.8031369074175481, 0.7794964087098919, 0.7658251006220271]\n",
      "F1 Score: [0.7903430367122668, 0.7804949923421727, 0.8011274135663131, 0.7755218360018017, 0.7750068965883548]\n",
      "F1 Score: [0.7920286677817654, 0.7856194690265487, 0.7954996158715102, 0.7806606625009866, 0.7614919507519142]\n",
      "F1 Score: [0.7986905410312274, 0.800250872657776, 0.798890284757119, 0.7768238227779718, 0.7731709731709732]\n",
      "F1 Score: [0.7927986596810487, 0.7987726302474505, 0.7981615848075578, 0.789671682626539, 0.7861911770890282]\n",
      "F1 Score: [0.8069958597995981, 0.8039436591806504, 0.8104457396824024, 0.779270684123452, 0.779270684123452]\n",
      "F1 Score: [0.8031914185886229, 0.7963651245455832, 0.8131238623428592, 0.7995360813772849, 0.7969824008852759]\n",
      "F1 Score: [0.803160411476332, 0.8065316511325558, 0.8130314486010165, 0.808161106174714, 0.779270684123452]\n",
      "F1 Score: [0.8000382111892903, 0.7981122854254354, 0.8026746861009134, 0.7954896956631032, 0.7838717995369056]\n",
      "F1 Score: [0.8000420290196633, 0.7979908650542176, 0.8109453082518264, 0.7969616482028666, 0.7867505083471455]\n",
      "F1 Score: [0.7906342182890855, 0.8102193196826157, 0.8150263498882666, 0.7908323130875059, 0.7930024565084246]\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'n_estimators': [100,200,250], 'max_depth':[5,10,20,None],'ccp_alpha':[0], 'max_features':['sqrt'],'n_jobs':[-1]}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X_POS, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X_POS[train_index],train_df_X_POS[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000, ngram_range=(1,3), stop_words=['_a','_n','_r','_v'])\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        rfc = RandomForestClassifier(**param)\n",
    "        rfc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = rfc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "    param_str = str(param)\n",
    "    print(\"F1 Score:\", param_f1)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"{'ccp_alpha': 0, 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 250, 'n_jobs': -1}\",\n",
       " 0.8020310603016141)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key_for_max_value(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 0.10002303123474121s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X_POS)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X_POS[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X_POS[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "rfc = RandomForestClassifier(ccp_alpha= 0, max_depth= 20, max_features= 'sqrt', n_estimators= 250, n_jobs= -1)\n",
    "rfc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text_POS)\n",
    "y_test_pred = rfc.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72       220\n",
      "           1       0.98      0.83      0.90       848\n",
      "\n",
      "    accuracy                           0.85      1068\n",
      "   macro avg       0.78      0.88      0.81      1068\n",
      "weighted avg       0.90      0.85      0.86      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF POS + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: [0.798231045449683, 0.8032970910314013, 0.8233272196991352, 0.8069573824451869, 0.8034802955569289]\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "param_grid = {'alpha':[1]}\n",
    "param_grid = ParameterGrid(param_grid)\n",
    "f1_scores = {}\n",
    "for param in param_grid:\n",
    "    param_f1 = []\n",
    "    for train_index, test_index in kf.split(train_df_X_POS, train_df_y):\n",
    "        #split into train and val\n",
    "        X_train, X_test = train_df_X_POS[train_index],train_df_X_POS[test_index]\n",
    "        y_train, y_test = train_df_y[train_index], train_df_y[test_index]\n",
    "\n",
    "        #Fit TFIDF vectorize on train first, then undersample\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000, ngram_range=(1,3), stop_words=['_a','_n','_r','_v'])\n",
    "        tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "\n",
    "        #Split into majority and minority for undersampling here\n",
    "        X_train_majority_class = X_train[y_train == 1]\n",
    "        y_train_majority_class = y_train[y_train == 1]\n",
    "        X_train_minority_class = X_train[y_train == 0]\n",
    "        y_train_minority_class = y_train[y_train == 0]\n",
    "\n",
    "        # Downsample majority class only\n",
    "        X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                                        replace=False,    # sample without replacement\n",
    "                                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                                        random_state=42)  # reproducible results\n",
    "\n",
    "        # Combine minority class with downsampled majority class\n",
    "        X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "        y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "        X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "        X_test_vector = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "        nbc = MultinomialNB(**param)\n",
    "        nbc.fit(X_train_vector, y_train_balanced)\n",
    "        \n",
    "        y_pred = nbc.predict(X_test_vector)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        param_f1.append(f1)\n",
    "    param_str = str(param)\n",
    "    print(\"F1 Score:\", param_f1)\n",
    "    f1_scores[param_str] = mean(param_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"{'alpha': 1}\", 0.8070586068364671)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key_for_max_value(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict test set = 0.07051753997802734s\n"
     ]
    }
   ],
   "source": [
    "# Fit optimal hyperparameters on entire train data\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_features=20000,ngram_range=(1,3))\n",
    "tfidf_vectorizer.fit(train_df_X_POS)\n",
    "\n",
    "\n",
    "#Split into majority and minority for undersampling here\n",
    "X_train_majority_class = train_df_X_POS[train_df_y == 1]\n",
    "y_train_majority_class = train_df_y[train_df_y == 1]\n",
    "X_train_minority_class = train_df_X_POS[train_df_y == 0]\n",
    "y_train_minority_class = train_df_y[train_df_y == 0]\n",
    "\n",
    "# Downsample majority class only\n",
    "X_train_majority_downsampled,y_train_majority_downsampled = resample(X_train_majority_class,y_train_majority_class, \n",
    "                        replace=False,    # sample without replacement\n",
    "                        n_samples=len(X_train_minority_class),   # to match minority class\n",
    "                        random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "X_train_balanced = pd.concat([X_train_majority_downsampled, X_train_minority_class])\n",
    "y_train_balanced = pd.concat([y_train_majority_downsampled, y_train_minority_class])\n",
    "\n",
    "\n",
    "X_train_vector = tfidf_vectorizer.transform(X_train_balanced)\n",
    "\n",
    "nbc = MultinomialNB()\n",
    "nbc.fit(X_train_vector, y_train_balanced)\n",
    "\n",
    "\n",
    "#Apply fitted model to test\n",
    "start = time()\n",
    "X_test_vector = tfidf_vectorizer.transform(testdf.cleaned_text_POS)\n",
    "y_test_pred = nbc.predict(X_test_vector)\n",
    "end = time()\n",
    "y_test_gt = testdf.Binary_anno\n",
    "print(f\"Time taken to predict test set = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15145.16814302909"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1068/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       220\n",
      "           1       0.98      0.81      0.88       848\n",
      "\n",
      "    accuracy                           0.83      1068\n",
      "   macro avg       0.77      0.87      0.79      1068\n",
      "weighted avg       0.89      0.83      0.85      1068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_gt, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
